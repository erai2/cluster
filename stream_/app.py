import streamlit as st
import sqlite3
import openai
import json
import time
from pathlib import Path
import pandas as pd
import os

# í™˜ê²½ì„¤ì •
DB_FILE = "terms.db"
openai.api_key = st.secrets["OPENAI_API_KEY"]

# DB ì´ˆê¸°í™”
def init_db():
    conn = sqlite3.connect(DB_FILE)
    c = conn.cursor()
    c.execute('''CREATE TABLE IF NOT EXISTS terms (
        id INTEGER PRIMARY KEY AUTOINCREMENT,
        category TEXT,
        term TEXT,
        definition TEXT,
        explanation TEXT,
        examples TEXT,
        rules TEXT,
        keywords TEXT,
        source_file TEXT
    )''')
    conn.commit()
    conn.close()

# í…ìŠ¤íŠ¸ ì¶”ì¶œ (txt, md, pdf, docx)
def extract_text(file):
    suffix = Path(file.name).suffix.lower()
    if suffix in [".txt", ".md"]:
        return file.read().decode("utf-8", errors="ignore")
    elif suffix == ".pdf":
        from pdfminer.high_level import extract_text
        tmp_path = Path("uploads") / f"{int(time.time())}.pdf"
        tmp_path.parent.mkdir(exist_ok=True)
        with open(tmp_path, "wb") as f:
            f.write(file.read())
        return extract_text(str(tmp_path))
    elif suffix in [".docx"]:
        import docx
        tmp_path = Path("uploads") / f"{int(time.time())}.docx"
        tmp_path.parent.mkdir(exist_ok=True)
        with open(tmp_path, "wb") as f:
            f.write(file.read())
        doc = docx.Document(str(tmp_path))
        return "\n".join([p.text for p in doc.paragraphs])
    else:
        st.error(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹: {suffix}")
        return ""

# AI êµ¬ì¡°í™”
def extract_terms(text, filename):
    prompt = f"""
    ì•„ë˜ ë¬¸ì„œì—ì„œ ì£¼ìš” ìš©ì–´, ì •ì˜, ì„¤ëª…, ì‚¬ë¡€, ê·œì¹™, í‚¤ì›Œë“œë¥¼ ë‹¤ìŒ JSON ë°°ì—´ êµ¬ì¡°ë¡œ ì¶œë ¥í•˜ì„¸ìš”.
    ë‹¨, ì›ë¬¸ì„ ìµœëŒ€í•œ ë³´ì¡´í•˜ê³  ëˆ„ë½ ì—†ì´ ì¶”ì¶œí•˜ì„¸ìš”.

    JSON í˜•ì‹:
    [
      {{
        "category": "...",
        "term": "...",
        "definition": "...",
        "explanation": "...",
        "examples": ["..."],
        "rules": ["..."],
        "keywords": ["..."],
        "source_file": "{filename}"
      }}
    ]

    ë¬¸ì„œ:
    {text}
    """
    resp = openai.ChatCompletion.create(
        model="gpt-4o-mini",
        messages=[{"role": "user", "content": prompt}],
        temperature=0
    )
    return json.loads(resp.choices[0].message.content)

# DB ì €ì¥
def save_to_db(data):
    conn = sqlite3.connect(DB_FILE)
    c = conn.cursor()
    for item in data:
        c.execute('''INSERT INTO terms (category, term, definition, explanation, examples, rules, keywords, source_file)
                     VALUES (?, ?, ?, ?, ?, ?, ?, ?)''',
                  (item.get('category'), item.get('term'), item.get('definition'),
                   item.get('explanation'), json.dumps(item.get('examples', []), ensure_ascii=False),
                   json.dumps(item.get('rules', []), ensure_ascii=False),
                   json.dumps(item.get('keywords', []), ensure_ascii=False),
                   item.get('source_file')))
    conn.commit()
    conn.close()

# UI
st.set_page_config(page_title="ë¬¸ì„œ â†’ ìš©ì–´ DB", layout="wide")
st.title("ğŸ“š ë¬¸ì„œ ì—…ë¡œë“œ â†’ AI êµ¬ì¡°í™” â†’ DB ì €ì¥")

init_db()

uploaded = st.file_uploader("ë¬¸ì„œ ì—…ë¡œë“œ", type=["txt", "md", "pdf", "docx"])
if uploaded:
    with st.spinner("í…ìŠ¤íŠ¸ ì¶”ì¶œ ì¤‘..."):
        text = extract_text(uploaded)
    if text:
        with st.spinner("AIë¡œ ìš©ì–´ êµ¬ì¡°í™” ì¤‘..."):
            terms = extract_terms(text, uploaded.name)
        save_to_db(terms)
        st.success(f"{len(terms)}ê°œì˜ ìš©ì–´ê°€ DBì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

st.subheader("ğŸ“‚ DB ì €ì¥ ë‚´ìš©")
conn = sqlite3.connect(DB_FILE)
df = pd.read_sql("SELECT * FROM terms", conn)
conn.close()
st.dataframe(df, use_container_width=True)